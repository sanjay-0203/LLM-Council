# ============================================
# LLM Council Configuration - Production Ready
# ============================================

# ============================================
# COUNCIL SETTINGS
# ============================================
council:
  name: "Open Source LLM Council"
  description: "Multi-model consensus system for better AI decisions"
  version: "1.0.0"
  
  # Voting configuration
  voting_method: "weighted"  # majority, weighted, unanimous, ranked, borda, approval
  min_agreement_threshold: 0.6
  require_consensus: false
  
  # Debate settings
  max_debate_rounds: 5
  enable_devil_advocate: true
  
  # Generation settings
  default_temperature: 0.7
  default_max_tokens: 2048
  default_top_p: 0.9
  
  # Performance
  parallel_execution: true
  max_concurrent: 5
  timeout_seconds: 120
  
  # Features
  enable_streaming: true
  enable_caching: true
  cache_ttl_seconds: 3600
  enable_persistence: true
  
  # Retry settings
  max_retries: 3
  retry_delay: 2
  exponential_backoff: true

# ============================================
# MODEL DEFINITIONS
# ============================================
models:
  # Primary Reasoners
  - name: "llama3.1:8b"
    role: "general_reasoner"
    description: "Balanced, well-rounded reasoning"
    weight: 1.0
    enabled: true
    temperature: 0.7
    max_tokens: 2048
    priority: 1
    tags: ["primary", "general"]
  
  - name: "llama3.1:70b"
    role: "senior_reasoner"
    description: "Deep, nuanced analysis"
    weight: 1.5
    enabled: false  # Enable if you have resources
    temperature: 0.6
    max_tokens: 4096
    priority: 0
    tags: ["primary", "advanced"]
  
  # Analytical Models
  - name: "mistral:7b"
    role: "analytical_thinker"
    description: "Logic-focused, evidence-based analysis"
    weight: 1.0
    enabled: true
    temperature: 0.5
    max_tokens: 2048
    priority: 1
    tags: ["analytical", "logic"]
  
  - name: "mixtral:8x7b"
    role: "expert_analyst"
    description: "Expert mixture for complex analysis"
    weight: 1.3
    enabled: false
    temperature: 0.6
    max_tokens: 4096
    priority: 0
    tags: ["analytical", "expert"]
  
  # Concise Responders
  - name: "phi3:medium"
    role: "concise_responder"
    description: "Brief, focused responses"
    weight: 0.8
    enabled: true
    temperature: 0.6
    max_tokens: 1024
    priority: 2
    tags: ["concise", "efficient"]
  
  - name: "phi3:mini"
    role: "quick_responder"
    description: "Fast, lightweight responses"
    weight: 0.6
    enabled: true
    temperature: 0.7
    max_tokens: 512
    priority: 3
    tags: ["concise", "fast"]
  
  # Creative Thinkers
  - name: "gemma2:9b"
    role: "creative_thinker"
    description: "Novel perspectives and ideas"
    weight: 0.9
    enabled: true
    temperature: 0.8
    max_tokens: 2048
    priority: 1
    tags: ["creative", "innovative"]
  
  # Technical Experts
  - name: "qwen2:7b"
    role: "technical_expert"
    description: "Technical accuracy and detail"
    weight: 1.0
    enabled: true
    temperature: 0.5
    max_tokens: 2048
    priority: 1
    tags: ["technical", "precise"]
  
  - name: "codellama:13b"
    role: "code_specialist"
    description: "Programming and technical implementation"
    weight: 1.1
    enabled: false
    temperature: 0.4
    max_tokens: 4096
    priority: 1
    tags: ["technical", "code"]
  
  # Specialized Roles
  - name: "solar:10.7b"
    role: "devil_advocate"
    description: "Challenges assumptions, finds weaknesses"
    weight: 0.9
    enabled: false
    temperature: 0.7
    max_tokens: 2048
    priority: 2
    tags: ["specialized", "critical"]
  
  - name: "neural-chat:7b"
    role: "synthesizer"
    description: "Combines and harmonizes perspectives"
    weight: 1.0
    enabled: false
    temperature: 0.6
    max_tokens: 2048
    priority: 2
    tags: ["specialized", "synthesis"]

# ============================================
# EVALUATION CRITERIA
# ============================================
evaluation_criteria:
  - name: "accuracy"
    description: "Factual correctness and truthfulness"
    weight: 1.0
    min_score: 1
    max_score: 10
  
  - name: "relevance"
    description: "How well the response addresses the question"
    weight: 0.95
    min_score: 1
    max_score: 10
  
  - name: "clarity"
    description: "Clear, understandable explanation"
    weight: 0.85
    min_score: 1
    max_score: 10
  
  - name: "completeness"
    description: "Comprehensive coverage of the topic"
    weight: 0.8
    min_score: 1
    max_score: 10
  
  - name: "reasoning"
    description: "Logical reasoning and argumentation quality"
    weight: 0.9
    min_score: 1
    max_score: 10
  
  - name: "coherence"
    description: "Internal consistency and flow"
    weight: 0.75
    min_score: 1
    max_score: 10
  
  - name: "depth"
    description: "Depth of insight and analysis"
    weight: 0.7
    min_score: 1
    max_score: 10
  
  - name: "practicality"
    description: "Actionable and useful information"
    weight: 0.65
    min_score: 1
    max_score: 10

# ============================================
# BACKEND CONFIGURATION
# ============================================
backends:
  # Ollama (Primary)
  ollama:
    enabled: true
    base_url: "http://localhost:11434"
    timeout: 120
    default_options:
      num_ctx: 4096
      num_gpu: 1
      num_thread: 8
  
  # vLLM (Optional - for high throughput)
  vllm:
    enabled: false
    api_url: "http://localhost:8000"
    api_key: ""
    default_options:
      max_tokens: 2048
  
  # LlamaCpp (Optional - for CPU/low memory)
  llamacpp:
    enabled: false
    model_path: "./models"
    default_options:
      n_ctx: 4096
      n_threads: 8

# ============================================
# PERSISTENCE SETTINGS
# ============================================
persistence:
  enabled: true
  database_url: "sqlite:///data/council.db"
  
  # What to store
  store_responses: true
  store_votes: true
  store_evaluations: true
  store_debates: true
  store_consensus: true
  
  # Retention
  retention_days: 90
  archive_old_records: true

# ============================================
# LOGGING CONFIGURATION
# ============================================
logging:
  level: "INFO"
  format: "structured"  # structured, simple, json
  
  # File logging
  file:
    enabled: true
    path: "logs/council.log"
    rotation: "10 MB"
    retention: "30 days"
    compression: "gz"
  
  # Console logging
  console:
    enabled: true
    colorize: true

# ============================================
# CACHING SETTINGS
# ============================================
caching:
  enabled: true
  backend: "memory"  # memory, redis, disk
  ttl_seconds: 3600
  max_size: 1000
  
  # Redis settings (if using redis backend)
  redis:
    host: "localhost"
    port: 6379
    db: 0

# ============================================
# CALIBRATION SETTINGS
# ============================================
calibration:
  enabled: true
  min_samples: 10
  update_frequency: "per_session"  # per_query, per_session, manual
  
  # Initial weights (adjusted based on performance)
  initial_weights:
    accuracy: 1.0
    speed: 0.5
    consistency: 0.8
